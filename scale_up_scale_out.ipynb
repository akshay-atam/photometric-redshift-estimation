{"cells":[{"cell_type":"markdown","id":"dadd8a40","metadata":{},"source":["## Creating Spark session"]},{"cell_type":"code","execution_count":1,"id":"4eb5a9af","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession\n","import pyspark.sql.types as T\n","\n","spark = SparkSession.builder.getOrCreate()"]},{"cell_type":"markdown","id":"a831643b","metadata":{},"source":["## Schema definition for the two files\n","The dataset had to be divided into two files. Defining the schema here. Being an astronomical data and a regression task, all the values are continuous."]},{"cell_type":"code","execution_count":2,"id":"e58167b3","metadata":{},"outputs":[],"source":["# schema 1\n","gal_info_schema = T.StructType([\n","    T.StructField('specObjID', T.LongType(), True),\n","    T.StructField('class', T.StringType(), True),\n","    T.StructField('z', T.FloatType(), True),\n","    T.StructField('zErr', T.FloatType(), True),\n","    T.StructField('ra', T.FloatType(), True),\n","    T.StructField('dec', T.FloatType(), True),\n","    T.StructField('zphot', T.FloatType(), True),\n","    T.StructField('dzphot', T.FloatType(), True),\n","    T.StructField('l', T.FloatType(), True),\n","    T.StructField('b', T.FloatType(), True),\n","])\n","\n","# schema 2\n","gal_petro_schema = T.StructType([\n","    T.StructField('specObjID', T.LongType(), True),\n","    T.StructField('petroMag_u', T.FloatType(), True),\n","    T.StructField('petroMag_g', T.FloatType(), True),\n","    T.StructField('petroMag_r', T.FloatType(), True),\n","    T.StructField('petroMag_i', T.FloatType(), True),\n","    T.StructField('petroMag_z', T.FloatType(), True),\n","    T.StructField('petroMagErr_u', T.FloatType(), True),\n","    T.StructField('petroMagErr_g', T.FloatType(), True),\n","    T.StructField('petroMagErr_r', T.FloatType(), True),\n","    T.StructField('petroMagErr_i', T.FloatType(), True),\n","    T.StructField('petroMagErr_z', T.FloatType(), True),\n","])"]},{"cell_type":"markdown","id":"80f11dd6","metadata":{},"source":["## Reading of the files with the created schema"]},{"cell_type":"code","execution_count":3,"id":"be4f06b9","metadata":{},"outputs":[],"source":["gal_info = spark.read.csv(\n","    path=\"gs://dataproc-staging-us-central1-931970996334-cxascqdj/notebooks/jupyter/gal.csv\",\n","    sep=\",\",\n","    header=True,\n","    schema=gal_info_schema\n",")\n","\n","gal_petro = spark.read.csv(\n","    path=\"gs://dataproc-staging-us-central1-931970996334-cxascqdj/notebooks/jupyter/gal_petro.csv\",\n","    sep=\",\",\n","    header=True,\n","    schema=gal_petro_schema\n",")"]},{"cell_type":"markdown","id":"28c4deb5","metadata":{},"source":["## Joining the two DataFrames"]},{"cell_type":"code","execution_count":4,"id":"34d5442b","metadata":{},"outputs":[],"source":["gal_data = gal_info.join(\n","    gal_petro,\n","    gal_info[\"specObjID\"] == gal_petro[\"specObjID\"]\n",")"]},{"cell_type":"markdown","id":"0f9dfd89","metadata":{},"source":["## Removing one key from joined data\n","Since the dataframes were joined on 'spechObjID', the joined table would have two instances of the primary key, removing one to avoid any ambiguity."]},{"cell_type":"code","execution_count":5,"id":"8ef55a44","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- specObjID: long (nullable = true)\n"," |-- class: string (nullable = true)\n"," |-- z: float (nullable = true)\n"," |-- zErr: float (nullable = true)\n"," |-- ra: float (nullable = true)\n"," |-- dec: float (nullable = true)\n"," |-- zphot: float (nullable = true)\n"," |-- dzphot: float (nullable = true)\n"," |-- l: float (nullable = true)\n"," |-- b: float (nullable = true)\n"," |-- petroMag_u: float (nullable = true)\n"," |-- petroMag_g: float (nullable = true)\n"," |-- petroMag_r: float (nullable = true)\n"," |-- petroMag_i: float (nullable = true)\n"," |-- petroMag_z: float (nullable = true)\n"," |-- petroMagErr_u: float (nullable = true)\n"," |-- petroMagErr_g: float (nullable = true)\n"," |-- petroMagErr_r: float (nullable = true)\n"," |-- petroMagErr_i: float (nullable = true)\n"," |-- petroMagErr_z: float (nullable = true)\n","\n"]}],"source":["gal_data = gal_data.drop(gal_petro[\"specObjID\"])\n","gal_data.printSchema()"]},{"cell_type":"markdown","id":"58226db7","metadata":{},"source":["## Creation of assembler and scaler"]},{"cell_type":"code","execution_count":6,"id":"e07b113d","metadata":{},"outputs":[],"source":["from pyspark.ml import Pipeline\n","from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n","from pyspark.ml.regression import LinearRegression\n","from pyspark.ml.evaluation import RegressionEvaluator\n","import time"]},{"cell_type":"code","execution_count":7,"id":"4e619b20","metadata":{},"outputs":[],"source":["feature_columns = [\n","    \"z\",\n","    \"zErr\",\n","    \"ra\",\n","    \"dec\",\n","    \"dzphot\",\n","    \"petroMag_u\",\n","    \"petroMag_g\",\n","    \"petroMag_r\",\n","    \"petroMag_i\",\n","    \"petroMag_z\",\n","    \"petroMagErr_u\",\n","    \"petroMagErr_g\",\n","    \"petroMagErr_r\",\n","    \"petroMagErr_i\",\n","    \"petroMagErr_z\"\n","]\n","\n","assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n","scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")"]},{"cell_type":"code","execution_count":8,"id":"0b575196","metadata":{},"outputs":[],"source":["# Linear Regression pipeline\n","train_data, test_data = gal_data.randomSplit([0.8, 0.2], seed=42)\n","evaluator = RegressionEvaluator(labelCol=\"zphot\", predictionCol=\"prediction\", metricName=\"r2\")"]},{"cell_type":"markdown","id":"d89ed6d1","metadata":{},"source":["## Linear Regression"]},{"cell_type":"code","execution_count":9,"id":"cee64bcf","metadata":{},"outputs":[],"source":["lr_best = LinearRegression(featuresCol=\"scaled_features\", labelCol=\"zphot\", regParam=0.2, elasticNetParam=1.0, loss='squaredError')\n","pipeline = Pipeline(stages=[assembler, scaler, lr_best])"]},{"cell_type":"code","execution_count":10,"id":"346f246e","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["23/12/17 00:10:07 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["With 25.0% data: 165.73 seconds.\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["With 50.0% data: 74.98 seconds.\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["With 75.0% data: 68.22 seconds.\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 138:=============================================>         (10 + 2) / 12]\r"]},{"name":"stdout","output_type":"stream","text":["With 100.0% data: 63.88 seconds.\n","With 25.0% data | R2: 1.0000 | RMSE: 0.2816\n","With 50.0% data | R2: 1.0000 | RMSE: 0.2809\n","With 75.0% data | R2: 1.0000 | RMSE: 0.2806\n","With 100.0% data | R2: 1.0000 | RMSE: 0.2812\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["evaluation_results = []\n","percentage_list = [0.25, 0.5, 0.75, 1.0]\n","\n","# Loop through different percentages\n","for percentage in percentage_list:\n","    start = time.time()\n","    sampled_data = gal_data.sample(fraction=percentage, seed=42)\n","    \n","    # Split data, train on train set, make predictions on test set\n","    train_data, test_data = sampled_data.randomSplit([0.8, 0.2], seed=42)\n","    model = pipeline.fit(train_data)\n","    predictions = model.transform(test_data)\n","\n","    # Evaluation - R2\n","    evaluator1 = RegressionEvaluator(labelCol=\"zphot\", predictionCol=\"prediction\", metricName=\"r2\")\n","    r2 = evaluator1.evaluate(predictions)\n","    # Evaluation - RMSE\n","    evaluator2 = RegressionEvaluator(labelCol=\"zphot\", predictionCol=\"prediction\", metricName=\"rmse\")\n","    rmse = evaluator2.evaluate(predictions)\n","\n","    # Append results to the list\n","    evaluation_results.append((percentage, r2, rmse))\n","    \n","    # Time for x% of data to complete\n","    print(f\"With {percentage * 100}% data: {(time.time() - start):.2f} seconds.\")\n","\n","# Print the evaluation results\n","for percentage, r2, rmse in evaluation_results:\n","    print(f\"With {percentage * 100}% data | R2: {r2:.4f} | RMSE: {rmse:.4f}\")"]},{"cell_type":"markdown","id":"2e2dfb75","metadata":{},"source":["## Decision Tree Regression"]},{"cell_type":"code","execution_count":11,"id":"aa2ae0c8","metadata":{},"outputs":[],"source":["from pyspark.ml.regression import DecisionTreeRegressor"]},{"cell_type":"code","execution_count":12,"id":"3c436fa9","metadata":{},"outputs":[],"source":["dtr_best = DecisionTreeRegressor(featuresCol=\"scaled_features\", labelCol=\"zphot\", maxDepth=5)\n","pipeline = Pipeline(stages=[assembler, scaler, dtr_best])"]},{"cell_type":"code","execution_count":13,"id":"59d6013e","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["With 25.0% data: 54.55 seconds.\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["With 50.0% data: 56.85 seconds.\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["With 75.0% data: 58.41 seconds.\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 350:==================================================>    (11 + 1) / 12]\r"]},{"name":"stdout","output_type":"stream","text":["With 100.0% data: 61.23 seconds.\n","With 25.0% data | R2: 0.9603 | RMSE: 160.4291\n","With 50.0% data | R2: 0.9521 | RMSE: 174.4568\n","With 75.0% data | R2: 0.9472 | RMSE: 182.6277\n","With 100.0% data | R2: 0.9523 | RMSE: 173.8204\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["evaluation_results = []\n","percentage_list = [0.25, 0.5, 0.75, 1.0]\n","\n","# Loop through different percentages\n","for percentage in percentage_list:\n","    start = time.time()\n","    sampled_data = gal_data.sample(fraction=percentage, seed=42)\n","    \n","    # Split data, train on train set, make predictions on test set\n","    train_data, test_data = sampled_data.randomSplit([0.8, 0.2], seed=42)\n","    model = pipeline.fit(train_data)\n","    predictions = model.transform(test_data)\n","\n","    # Evaluation - R2\n","    evaluator1 = RegressionEvaluator(labelCol=\"zphot\", predictionCol=\"prediction\", metricName=\"r2\")\n","    r2 = evaluator1.evaluate(predictions)\n","    # Evaluation - RMSE\n","    evaluator2 = RegressionEvaluator(labelCol=\"zphot\", predictionCol=\"prediction\", metricName=\"rmse\")\n","    rmse = evaluator2.evaluate(predictions)\n","\n","    # Append results to the list\n","    evaluation_results.append((percentage, r2, rmse))\n","    \n","    # Time for x% of data to complete\n","    print(f\"With {percentage * 100}% data: {(time.time() - start):.2f} seconds.\")\n","\n","# Print the evaluation results\n","for percentage, r2, rmse in evaluation_results:\n","    print(f\"With {percentage * 100}% data | R2: {r2:.4f} | RMSE: {rmse:.4f}\")"]},{"cell_type":"markdown","id":"14a195ca","metadata":{},"source":["## Random forest Regression"]},{"cell_type":"code","execution_count":14,"id":"737d58a6","metadata":{},"outputs":[],"source":["from pyspark.ml.regression import RandomForestRegressor"]},{"cell_type":"code","execution_count":15,"id":"68df3149","metadata":{},"outputs":[],"source":["rfr_best = RandomForestRegressor(featuresCol=\"scaled_features\", labelCol=\"zphot\", numTrees=4 , featureSubsetStrategy='onethird')\n","pipeline = Pipeline(stages=[assembler, scaler, rfr_best])"]},{"cell_type":"code","execution_count":16,"id":"3dc3020f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING: An illegal reflective access operation has occurred                    \n","WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/usr/lib/spark/jars/spark-core_2.12-3.3.2.jar) to field java.nio.charset.Charset.name\n","WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["With 25.0% data: 57.34 seconds.\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["With 50.0% data: 43.26 seconds.\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 509:==============================================>        (11 + 2) / 13]\r"]},{"name":"stdout","output_type":"stream","text":["With 75.0% data: 43.28 seconds.\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 562:==================================================>    (12 + 1) / 13]\r"]},{"name":"stdout","output_type":"stream","text":["With 100.0% data: 44.53 seconds.\n","With 25.0% data | R2: 0.9093 | RMSE: 238.5070\n","With 50.0% data | R2: 0.9350 | RMSE: 205.2915\n","With 75.0% data | R2: 0.9318 | RMSE: 211.8675\n","With 100.0% data | R2: 0.9157 | RMSE: 234.7890\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["evaluation_results = []\n","percentage_list = [0.25, 0.5, 0.75, 1.0]\n","\n","# Loop through different percentages\n","for percentage in percentage_list:\n","    start = time.time()\n","    sampled_data = gal_data.sample(fraction=percentage, seed=42)\n","    \n","    # Split data, train on train set, make predictions on test set\n","    train_data, test_data = sampled_data.randomSplit([0.8, 0.2], seed=42)\n","    model = pipeline.fit(train_data)\n","    predictions = model.transform(test_data)\n","\n","    # Evaluation - R2\n","    evaluator1 = RegressionEvaluator(labelCol=\"zphot\", predictionCol=\"prediction\", metricName=\"r2\")\n","    r2 = evaluator1.evaluate(predictions)\n","    # Evaluation - RMSE\n","    evaluator2 = RegressionEvaluator(labelCol=\"zphot\", predictionCol=\"prediction\", metricName=\"rmse\")\n","    rmse = evaluator2.evaluate(predictions)\n","\n","    # Append results to the list\n","    evaluation_results.append((percentage, r2, rmse))\n","    \n","    # Time for x% of data to complete\n","    print(f\"With {percentage * 100}% data: {(time.time() - start):.2f} seconds.\")\n","\n","# Print the evaluation results\n","for percentage, r2, rmse in evaluation_results:\n","    print(f\"With {percentage * 100}% data | R2: {r2:.4f} | RMSE: {rmse:.4f}\")"]},{"cell_type":"markdown","id":"ad9934f1","metadata":{},"source":["## Gradient Boosted Tree Regression"]},{"cell_type":"code","execution_count":17,"id":"dbed913c","metadata":{},"outputs":[],"source":["from pyspark.ml.regression import GBTRegressor"]},{"cell_type":"code","execution_count":18,"id":"9fafaadd","metadata":{},"outputs":[],"source":["gbtr_best = GBTRegressor(featuresCol=\"scaled_features\", labelCol=\"zphot\", lossType='squared')\n","pipeline = Pipeline(stages=[assembler, scaler, gbtr_best])"]},{"cell_type":"code","execution_count":19,"id":"84b755cf","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["With 25.0% data: 69.90 seconds.\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["With 50.0% data: 76.22 seconds.\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["With 75.0% data: 81.13 seconds.\n"]},{"name":"stderr","output_type":"stream","text":["[Stage 2302:=============================================>        (11 + 2) / 13]\r"]},{"name":"stdout","output_type":"stream","text":["With 100.0% data: 86.74 seconds.\n","With 25.0% data | R2: 0.9613 | RMSE: 155.7864\n","With 50.0% data | R2: 0.9682 | RMSE: 143.5513\n","With 75.0% data | R2: 0.9675 | RMSE: 146.3123\n","With 100.0% data | R2: 0.9678 | RMSE: 145.1515\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["evaluation_results = []\n","percentage_list = [0.25, 0.5, 0.75, 1.0]\n","\n","# Loop through different percentages\n","for percentage in percentage_list:\n","    start = time.time()\n","    sampled_data = gal_data.sample(fraction=percentage, seed=42)\n","    \n","    # Split data, train on train set, make predictions on test set\n","    train_data, test_data = sampled_data.randomSplit([0.8, 0.2], seed=42)\n","    model = pipeline.fit(train_data)\n","    predictions = model.transform(test_data)\n","\n","    # Evaluation - R2\n","    evaluator1 = RegressionEvaluator(labelCol=\"zphot\", predictionCol=\"prediction\", metricName=\"r2\")\n","    r2 = evaluator1.evaluate(predictions)\n","    # Evaluation - RMSE\n","    evaluator2 = RegressionEvaluator(labelCol=\"zphot\", predictionCol=\"prediction\", metricName=\"rmse\")\n","    rmse = evaluator2.evaluate(predictions)\n","\n","    # Append results to the list\n","    evaluation_results.append((percentage, r2, rmse))\n","    \n","    # Time for x% of data to complete\n","    print(f\"With {percentage * 100}% data: {(time.time() - start):.2f} seconds.\")\n","\n","# Print the evaluation results\n","for percentage, r2, rmse in evaluation_results:\n","    print(f\"With {percentage * 100}% data | R2: {r2:.4f} | RMSE: {rmse:.4f}\")"]},{"cell_type":"code","execution_count":null,"id":"4386cff5","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}